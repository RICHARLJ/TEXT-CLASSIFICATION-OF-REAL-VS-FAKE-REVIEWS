{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFW6NjN9PSfK",
        "outputId": "e80e57bf-ee9b-443f-9d61-f751265aae2f"
      },
      "source": [
        "import csv                               # csv reader\n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.classify import SklearnClassifier\n",
        "from random import shuffle\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZvPx9BfPSfN"
      },
      "source": [
        "# load data from a file and append it to the rawData\n",
        "def loadData(path, Text=None):\n",
        "    with open(path) as f:\n",
        "        reader = csv.reader(f, delimiter='\\t')\n",
        "        for line in reader:\n",
        "            if line[0] == \"DOC_ID\":  # skip the header\n",
        "                continue\n",
        "            (Id, Text, Label) = parseReview(line)\n",
        "            rawData.append((Id, Text, Label))\n",
        "          \n",
        "\n",
        "\n",
        "def splitData(percentage):\n",
        "    # A method to split the data between trainData and testData \n",
        "    dataSamples = len(rawData)\n",
        "    halfOfData = int(len(rawData)/2)\n",
        "    trainingSamples = int((percentage*dataSamples)/2)\n",
        "    for (_, Text, Label) in rawData[:trainingSamples] + rawData[halfOfData:halfOfData+trainingSamples]:\n",
        "        trainData.append((toFeatureVector(preProcess(Text)),Label))\n",
        "    for (_, Text, Label) in rawData[trainingSamples:halfOfData] + rawData[halfOfData+trainingSamples:]:\n",
        "        testData.append((toFeatureVector(preProcess(Text)),Label))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDHtGPK5PSfN"
      },
      "source": [
        "# Question 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW3OLzFxPSfO"
      },
      "source": [
        "# Convert line from input file into an id/text/label tuple\n",
        "def parseReview(reviewLine):\n",
        "    # Should return a triple of an integer, a string containing the review, and a string indicating the label\n",
        "    # According to analysed amazon review text, we define reviews with label 1 as fake reviews, and reviews with lable 2 as real reviews.\n",
        "    # And then we show the doc ID, the review text and if it is a fake review or not for each review.\n",
        "    s=''\n",
        "    if reviewLine[1]=='__label1__':\n",
        "      s = 'fake'\n",
        "    else:\n",
        "      s = 'real'\n",
        "    return (reviewLine[0], reviewLine[8], s)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABTHHIGIPSfO"
      },
      "source": [
        "# TEXT PREPROCESSING AND FEATURE VECTORIZATION\n",
        "# Input: a string of one review\n",
        "def preProcess(text):\n",
        "    # Should return a list of tokens\n",
        "    # We  extract the tokens from string of characters by using tokenize and define it as perProcess(text), using NLTK's recommended word tokenizer \n",
        "    return word_tokenize (text)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7uNOsWQPSfO"
      },
      "source": [
        "# Question 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1V8gqHXPSfO"
      },
      "source": [
        "featureDict = {} # A global dictionary of features\n",
        "\n",
        "def toFeatureVector(tokens):\n",
        "    # Should return a dictionary containing features as keys, and weights as values\n",
        "    # count the number of occurrences of each token from feature dictionary, and save counted tokens in local dictionary\n",
        "  localDict = {}\n",
        "  for token in tokens:\n",
        "    if token not in featureDict:\n",
        "      featureDict[token] = 1\n",
        "    else:\n",
        "      featureDict[token] += 1\n",
        "    if token not in localDict:\n",
        "      localDict[token] = 1\n",
        "    else:\n",
        "      localDict[token] += 1\n",
        "\n",
        "  return localDict"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATAzeZJ1PSfP"
      },
      "source": [
        "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
        "def trainClassifier(trainData):\n",
        "    print(\"Training Classifier...\")\n",
        "    pipeline =  Pipeline([('svc', LinearSVC())])\n",
        "    return SklearnClassifier(pipeline).train(trainData)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qr2rS3NPSfQ"
      },
      "source": [
        "# Question 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSVV0gGtPSfQ"
      },
      "source": [
        "def crossValidate(dataset, folds):\n",
        "    shuffle(dataset)\n",
        "    cv_results = []\n",
        "    foldSize = int(len(dataset)/folds)\n",
        "    # \n",
        "    for i in range(0,len(dataset),foldSize):\n",
        "        classifier = trainClassifier(dataset[:i]+dataset[foldSize+i:])\n",
        "        y_pred = predictLabels(dataset[i:i+foldSize],classifier)\n",
        "        a = accuracy_score(list(map(lambda d : d[1], dataset[i:i+foldSize])), y_pred)\n",
        "        (p,r,f,_) = precision_recall_fscore_support(list(map(lambda d : d[1], dataset[i:i+foldSize])), y_pred, average ='macro')\n",
        "        #print(a,p,r,f)\n",
        "        cv_results.append((a,p,r,f))\n",
        "    cv_results = (np.mean(np.array(cv_results),axis=0))\n",
        "    return cv_results"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0cN5EM5PSfQ"
      },
      "source": [
        "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
        "\n",
        "def predictLabels(reviewSamples, classifier):\n",
        "    return classifier.classify_many(map(lambda t: t[0], reviewSamples))\n",
        "\n",
        "def predictLabel(reviewSample, classifier):\n",
        "    return classifier.classify(toFeatureVector(preProcess(reviewSample)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHEsvdgvPSfR",
        "outputId": "ba43b205-1e11-4fd8-8586-dc2b45587679"
      },
      "source": [
        "# MAIN\n",
        "\n",
        "# loading reviews\n",
        "# initialize global lists that will be appended to by the methods below\n",
        "rawData = []          # the filtered data from the dataset file (should be 21000 samples)\n",
        "trainData = []        # the pre-processed training data as a percentage of the total dataset (currently 80%, or 16800 samples)\n",
        "testData = []         # the pre-processed test data as a percentage of the total dataset (currently 20%, or 4200 samples)\n",
        "\n",
        "# the output classes\n",
        "fakeLabel = 'fake'\n",
        "realLabel = 'real'\n",
        "\n",
        "# references to the data files\n",
        "reviewPath = 'amazon_reviews.txt'\n",
        "\n",
        "# Do the actual stuff (i.e. call the functions we've made)\n",
        "# We parse the dataset and put it in a raw data list\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Preparing the dataset...\",sep='\\n')\n",
        "loadData(reviewPath) \n",
        "\n",
        "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
        "# You do the cross validation on the 80% (training data)\n",
        "# We print the number of training samples and the number of features before the split\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Preparing training and test data...\",sep='\\n')\n",
        "splitData(0.8)\n",
        "# We print the number of training samples and the number of features after the split\n",
        "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Training Samples: \", len(trainData), \"Features: \", len(featureDict), sep='\\n')\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now 0 rawData, 0 trainData, 0 testData\n",
            "Preparing the dataset...\n",
            "Now 21000 rawData, 0 trainData, 0 testData\n",
            "Preparing training and test data...\n",
            "After split, 21000 rawData, 16800 trainData, 4200 testData\n",
            "Training Samples: \n",
            "16800\n",
            "Features: \n",
            "53734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WabN9DO6r6g2",
        "outputId": "fec7f0a4-ace6-46e0-a171-e2ac6e46b915"
      },
      "source": [
        "# QUESTION 3 - Make sure there is a function call here to the\n",
        "# crossValidate function on the training set to get your results\n",
        "print(f\"Mean of cross-validations (Accuracy, Precision, Recall, Fscore: {crossValidate(trainData, 10)}\") "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Classifier...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Mean of cross-validations (Accuracy, Precision, Recall, Fscore: [0.61583333 0.61590994 0.61580144 0.6155335 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGWU2i9nPSfR"
      },
      "source": [
        "# Evaluate on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJZkAC8HPSfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de609ff-a991-4730-fa69-3f5dea016485"
      },
      "source": [
        "# Finally, check the accuracy of your classifier by training on all the tranin data\n",
        "# and testing on the test set\n",
        "# Will only work once all functions are complete\n",
        "functions_complete = True  # set to True once you're happy with your methods for cross val\n",
        "if functions_complete:\n",
        "    print(testData[0])   # have a look at the first test data instance\n",
        "    classifier = trainClassifier(trainData)  # train the classifier\n",
        "    testTrue = [t[1] for t in testData]   # get the ground-truth labels from the data\n",
        "    testPred = predictLabels(testData, classifier)  # classify the test data to get predicted labels\n",
        "    finalScores = precision_recall_fscore_support(testTrue, testPred, average='weighted') # evaluate\n",
        "    print(\"Done training!\")\n",
        "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % finalScores[:3])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'This': 1, 'assortment': 1, 'is': 1, 'really': 1, 'Hershey': 1, \"'s\": 1, 'at': 1, 'their': 1, 'best': 1, '.': 2, 'The': 1, 'little': 1, 'ones': 1, 'are': 1, 'always': 1, 'excited': 1, 'whenever': 1, 'the': 1, 'holidays': 1, 'come': 1, 'because': 1, 'of': 1, 'this': 1}, 'fake')\n",
            "Training Classifier...\n",
            "Done training!\n",
            "Precision: 0.594550\n",
            "Recall: 0.594524\n",
            "F Score:0.594496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVi7VL3rPSfS"
      },
      "source": [
        "# Questions 4 and 5\n",
        "Once you're happy with your functions for Questions 1 to 3, it's advisable you make a copy of this notebook to make a new notebook, and then within it adapt and improve all three functions in the ways asked for in questions 4 and 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "aVpWhDM-PLnv",
        "outputId": "0f394238-c9c9-4707-a549-cda675d834fd"
      },
      "source": [
        "!pip install --upgrade --force-reinstall nltk==3.4\n",
        "import nltk\n",
        "print(nltk.__version__)\n",
        "import csv                               # csv reader\n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.classify import SklearnClassifier\n",
        "from random import shuffle\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.util import ngrams\n",
        "import string"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /root/.cache/pip/wheels/4b/c8/24/b2343664bcceb7147efeb21c0b23703a05b23fcfeaceaa2a1e/nltk-3.4-cp37-none-any.whl\n",
            "Collecting six\n",
            "  Using cached https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
            "Collecting singledispatch\n",
            "  Using cached https://files.pythonhosted.org/packages/cd/d1/6a9e922826e03f5af7bf348cfb75bcb0bc4c67e19c36805c2545f34427e5/singledispatch-3.6.2-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement six~=1.15.0, but you'll have six 1.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, singledispatch, nltk\n",
            "  Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Found existing installation: singledispatch 3.6.2\n",
            "    Uninstalling singledispatch-3.6.2:\n",
            "      Successfully uninstalled singledispatch-3.6.2\n",
            "  Found existing installation: nltk 3.4\n",
            "    Uninstalling nltk-3.4:\n",
            "      Successfully uninstalled nltk-3.4\n",
            "Successfully installed nltk-3.4 singledispatch-3.6.2 six-1.16.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "3.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6_PaDjIPLnz"
      },
      "source": [
        "# load data from a file and append it to the rawData\n",
        "def loadData(path, Text=None):\n",
        "    with open(path) as f:\n",
        "        reader = csv.reader(f, delimiter='\\t')\n",
        "        for line in reader:\n",
        "            if line[0] == \"DOC_ID\":  # skip the header\n",
        "                continue\n",
        "            (Id, Text, Label) = parseReview(line)\n",
        "            rawData.append((Id, Text, Label))\n",
        "          \n",
        "\n",
        "\n",
        "def splitData(percentage):\n",
        "    # A method to split the data between trainData and testData \n",
        "    dataSamples = len(rawData)\n",
        "    halfOfData = int(len(rawData)/2)\n",
        "    trainingSamples = int((percentage*dataSamples)/2)\n",
        "    for (_, Text, Label) in rawData[:trainingSamples] + rawData[halfOfData:halfOfData+trainingSamples]:\n",
        "        trainData.append((toFeatureVector(preProcess(Text)),Label))\n",
        "    for (_, Text, Label) in rawData[trainingSamples:halfOfData] + rawData[halfOfData+trainingSamples:]:\n",
        "        testData.append((toFeatureVector(preProcess(Text)),Label))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TNdBrU2PLnz"
      },
      "source": [
        "# Question 4.1, 4.2 including lemmatization, remove stop words as well as punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoxluJ-fPLn0"
      },
      "source": [
        "# Convert line from input file into an id/text/label tuple\n",
        "def parseReview(reviewLine):\n",
        "    # Should return a triple of an integer, a string containing the review, and a string indicating the label\n",
        "    s=''\n",
        "    if reviewLine[1]=='__label1__':\n",
        "      s = 'fake'\n",
        "    else:\n",
        "      s = 'real'\n",
        "    return (reviewLine[0], reviewLine[8], s)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Bxl7CqPLn0"
      },
      "source": [
        "table = str.maketrans({key: None for key in string.punctuation})\n",
        "\n",
        "def preProcess(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    filtered_tokens=[]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = text.translate(table)\n",
        "    for w in text.split(\" \"):\n",
        "        if w not in stop_words:\n",
        "            filtered_tokens.append(lemmatizer.lemmatize(w.lower()))\n",
        "    return filtered_tokens"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7eWTC4KPLn0"
      },
      "source": [
        "featureDict = {} # A global dictionary of features\n",
        "\n",
        "def toFeatureVector(tokens):\n",
        "    # Should return a dictionary containing features as keys, and weights as values\n",
        "    # DESCRIBE YOUR METHOD IN WORDS\n",
        "  localDict = {}\n",
        "  for token in tokens:\n",
        "    if token not in featureDict:\n",
        "      featureDict[token] = 1\n",
        "    else:\n",
        "      featureDict[token] += 1\n",
        "    if token not in localDict:\n",
        "      localDict[token] = 1\n",
        "    else:\n",
        "      localDict[token] += 1\n",
        "\n",
        "  return localDict"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFHRHn00PLn0"
      },
      "source": [
        "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
        "def trainClassifier(trainData):\n",
        "    print(\"Training Classifier...\")\n",
        "    pipeline =  Pipeline([('svc', LinearSVC())])\n",
        "    return SklearnClassifier(pipeline).train(trainData)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8QV4mfgPLn1"
      },
      "source": [
        "def crossValidate(dataset, folds):\n",
        "    shuffle(dataset)\n",
        "    cv_results = []\n",
        "    foldSize = int(len(dataset)/folds)\n",
        "    # DESCRIBE YOUR METHOD IN WORDS\n",
        "    for i in range(0,len(dataset),foldSize):\n",
        "        classifier = trainClassifier(dataset[:i]+dataset[foldSize+i:])\n",
        "        y_pred = predictLabels(dataset[i:i+foldSize],classifier)\n",
        "        a = accuracy_score(list(map(lambda d : d[1], dataset[i:i+foldSize])), y_pred)\n",
        "        (p,r,f,_) = precision_recall_fscore_support(list(map(lambda d : d[1], dataset[i:i+foldSize])), y_pred, average ='macro')\n",
        "        #print(a,p,r,f)\n",
        "        cv_results.append((a,p,r,f))\n",
        "    cv_results = (np.mean(np.array(cv_results),axis=0))\n",
        "    return cv_results"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz6TCk9fPLn1"
      },
      "source": [
        "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
        "\n",
        "def predictLabels(reviewSamples, classifier):\n",
        "    return classifier.classify_many(map(lambda t: t[0], reviewSamples))\n",
        "\n",
        "def predictLabel(reviewSample, classifier):\n",
        "    return classifier.classify(toFeatureVector(preProcess(reviewSample)))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQd9KbM4PLn1",
        "outputId": "134ca455-f34c-4331-9c6d-8ecbfec24a8b"
      },
      "source": [
        "# MAIN\n",
        "\n",
        "# loading reviews\n",
        "# initialize global lists that will be appended to by the methods below\n",
        "rawData = []          # the filtered data from the dataset file (should be 21000 samples)\n",
        "trainData = []        # the pre-processed training data as a percentage of the total dataset (currently 80%, or 16800 samples)\n",
        "testData = []         # the pre-processed test data as a percentage of the total dataset (currently 20%, or 4200 samples)\n",
        "\n",
        "# the output classes\n",
        "fakeLabel = 'fake'\n",
        "realLabel = 'real'\n",
        "\n",
        "# references to the data files\n",
        "reviewPath = 'amazon_reviews.txt'\n",
        "\n",
        "# Do the actual stuff (i.e. call the functions we've made)\n",
        "# We parse the dataset and put it in a raw data list\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Preparing the dataset...\",sep='\\n')\n",
        "loadData(reviewPath) \n",
        "\n",
        "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
        "# You do the cross validation on the 80% (training data)\n",
        "# We print the number of training samples and the number of features before the split\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Preparing training and test data...\",sep='\\n')\n",
        "splitData(0.8)\n",
        "# We print the number of training samples and the number of features after the split\n",
        "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Training Samples: \", len(trainData), \"Features: \", len(featureDict), sep='\\n')\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now 0 rawData, 0 trainData, 0 testData\n",
            "Preparing the dataset...\n",
            "Now 21000 rawData, 0 trainData, 0 testData\n",
            "Preparing training and test data...\n",
            "After split, 21000 rawData, 16800 trainData, 4200 testData\n",
            "Training Samples: \n",
            "16800\n",
            "Features: \n",
            "42400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoFLUg-U91rP",
        "outputId": "9d458e97-4a85-41bb-f718-8679bfefe4aa"
      },
      "source": [
        "# crossValidate function on the training set to get your results\n",
        "print(f\"Mean of cross-validations (Accuracy, Precision, Recall, Fscore: {crossValidate(trainData, 10)}\") "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Classifier...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Mean of cross-validations (Accuracy, Precision, Recall, Fscore: [0.63303571 0.63318843 0.63295024 0.63277825]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3OAB94uPLn2"
      },
      "source": [
        "# Evaluate on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX66_3P1PLn2",
        "outputId": "c02b6f1e-cf22-4d60-d183-6bc0180c2c52"
      },
      "source": [
        "# Finally, check the accuracy of your classifier by training on all the tranin data\n",
        "# and testing on the test set\n",
        "# Will only work once all functions are complete\n",
        "functions_complete = True  # set to True once you're happy with your methods for cross val\n",
        "if functions_complete:\n",
        "    print(testData[0])   # have a look at the first test data instance\n",
        "    classifier = trainClassifier(trainData)  # train the classifier\n",
        "    testTrue = [t[1] for t in testData]   # get the ground-truth labels from the data\n",
        "    testPred = predictLabels(testData, classifier)  # classify the test data to get predicted labels\n",
        "    finalScores = precision_recall_fscore_support(testTrue, testPred, average='weighted') # evaluate\n",
        "    print(\"Done training!\")\n",
        "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % finalScores[:3])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'this': 1, 'assortment': 1, 'really': 1, 'hershey': 1, 'best': 1, 'the': 1, 'little': 1, 'one': 1, 'always': 1, 'excited': 1, 'whenever': 1, 'holiday': 1, 'come': 1}, 'fake')\n",
            "Training Classifier...\n",
            "Done training!\n",
            "Precision: 0.597620\n",
            "Recall: 0.597619\n",
            "F Score:0.597618\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "262ky3AbgYWI"
      },
      "source": [
        "# **including lemmatization, remove stop words as well as punctuations would slightly improve the accuracy.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68aUF6POAeBz"
      },
      "source": [
        "# Question 4.3, 4.4 introduce the bigrams and test linearsvc function with different C values.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL3doxNACUkS"
      },
      "source": [
        "# Convert line from input file into an id/text/label tuple\n",
        "def parseReview(reviewLine):\n",
        "    # Should return a triple of an integer, a string containing the review, and a string indicating the label\n",
        "    s=''\n",
        "    if reviewLine[1]=='__label1__':\n",
        "      s = 'fake'\n",
        "    else:\n",
        "      s = 'real'\n",
        "    return (reviewLine[0], reviewLine[8], s)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ulc52cNQBJHy"
      },
      "source": [
        "table = str.maketrans({key: None for key in string.punctuation})\n",
        "def preProcess(text):\n",
        "    # Should return a list of tokens\n",
        "    lemmatizer = wordnet()\n",
        "    filtered_tokens=[]\n",
        "    lemmatized_tokens = []\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = text.translate(table)\n",
        "    for w in text.split(\" \"):\n",
        "        if w not in stop_words:\n",
        "            lemmatized_tokens.append(lemmatizer.lemmatize(w.lower()))\n",
        "        filtered_tokens = [' '.join(l) for l in nltk.bigrams(lemmatized_tokens)] + lemmatized_tokens\n",
        "    return filtered_tokens"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drvn-qyvEdAQ"
      },
      "source": [
        "table = str.maketrans({key: None for key in string.punctuation})\n",
        "\n",
        "def preProcess(text):\n",
        "    lemmatizer = wordnet()\n",
        "    filtered_tokens=[]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = text.translate(table)\n",
        "    for w in text.split(\" \"):\n",
        "        if w not in stop_words:\n",
        "            filtered_tokens.append(lemmatizer.lemmatize(w.lower()))\n",
        "    return filtered_tokens"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA00US1XEbcZ"
      },
      "source": [
        "table = str.maketrans({key: None for key in string.punctuation})\n",
        "\n",
        "def preProcess(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    filtered_tokens=[]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = text.translate(table)\n",
        "    for w in text.split(\" \"):\n",
        "        if w not in stop_words:\n",
        "            filtered_tokens.append(lemmatizer.lemmatize(w.lower()))\n",
        "    return filtered_tokens"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_Hl85m5ClRw"
      },
      "source": [
        "featureDict = {} # A global dictionary of features\n",
        "\n",
        "def toFeatureVector(tokens):\n",
        "    # Should return a dictionary containing features as keys, and weights as values\n",
        "    # DESCRIBE YOUR METHOD IN WORDS\n",
        "  localDict = {}\n",
        "  for token in tokens:\n",
        "    if token not in featureDict:\n",
        "      featureDict[token] = 1\n",
        "    else:\n",
        "      featureDict[token] += 1\n",
        "    if token not in localDict:\n",
        "      localDict[token] = 1\n",
        "    else:\n",
        "      localDict[token] += 1\n",
        "\n",
        "  return localDict"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JUEi76cBJO2"
      },
      "source": [
        "def trainClassifier(trainData):\n",
        "    print(\"Training Classifier...\")\n",
        "    pipeline =  Pipeline([('svc', LinearSVC(C=0.001))])\n",
        "    return SklearnClassifier(pipeline).train(trainData)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju5Up0xXC57J"
      },
      "source": [
        "def crossValidate(dataset, folds):\n",
        "    shuffle(dataset)\n",
        "    cv_results = []\n",
        "    foldSize = int(len(dataset)/folds)\n",
        "    # DESCRIBE YOUR METHOD IN WORDS\n",
        "    for i in range(0,len(dataset),foldSize):\n",
        "        classifier = trainClassifier(dataset[:i]+dataset[foldSize+i:])\n",
        "        y_pred = predictLabels(dataset[i:i+foldSize],classifier)\n",
        "        a = accuracy_score(list(map(lambda d : d[1], dataset[i:i+foldSize])), y_pred)\n",
        "        (p,r,f,_) = precision_recall_fscore_support(list(map(lambda d : d[1], dataset[i:i+foldSize])), y_pred, average ='macro')\n",
        "        #print(a,p,r,f)\n",
        "        cv_results.append((a,p,r,f))\n",
        "    cv_results = (np.mean(np.array(cv_results),axis=0))\n",
        "    return cv_results"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG-t2BuQC-p7"
      },
      "source": [
        "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
        "\n",
        "def predictLabels(reviewSamples, classifier):\n",
        "    return classifier.classify_many(map(lambda t: t[0], reviewSamples))\n",
        "\n",
        "def predictLabel(reviewSample, classifier):\n",
        "    return classifier.classify(toFeatureVector(preProcess(reviewSample)))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lj2FoYLBJRp",
        "outputId": "7871d7eb-41ab-4dc1-dee9-264f9e27e599"
      },
      "source": [
        "# MAIN\n",
        "\n",
        "# loading reviews\n",
        "# initialize global lists that will be appended to by the methods below\n",
        "rawData = []          # the filtered data from the dataset file (should be 21000 samples)\n",
        "trainData = []        # the pre-processed training data as a percentage of the total dataset (currently 80%, or 16800 samples)\n",
        "testData = []         # the pre-processed test data as a percentage of the total dataset (currently 20%, or 4200 samples)\n",
        "\n",
        "# the output classes\n",
        "fakeLabel = 'fake'\n",
        "realLabel = 'real'\n",
        "\n",
        "# references to the data files\n",
        "reviewPath = 'amazon_reviews.txt'\n",
        "\n",
        "# Do the actual stuff (i.e. call the functions we've made)\n",
        "# We parse the dataset and put it in a raw data list\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Preparing the dataset...\",sep='\\n')\n",
        "loadData(reviewPath) \n",
        "\n",
        "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
        "# You do the cross validation on the 80% (training data)\n",
        "# We print the number of training samples and the number of features before the split\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Preparing training and test data...\",sep='\\n')\n",
        "splitData(0.8)\n",
        "# We print the number of training samples and the number of features after the split\n",
        "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Training Samples: \", len(trainData), \"Features: \", len(featureDict), sep='\\n')\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now 0 rawData, 0 trainData, 0 testData\n",
            "Preparing the dataset...\n",
            "Now 21000 rawData, 0 trainData, 0 testData\n",
            "Preparing training and test data...\n",
            "After split, 21000 rawData, 16800 trainData, 4200 testData\n",
            "Training Samples: \n",
            "16800\n",
            "Features: \n",
            "42400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HQvocv_Bea-",
        "outputId": "6bc16175-e347-4dbc-81ac-3c8c73501704"
      },
      "source": [
        "# crossValidate function on the training set to get your results\n",
        "print(f\"Mean of cross-validations (Accuracy, Precision, Recall, Fscore: {crossValidate(trainData, 10)}\") "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Mean of cross-validations (Accuracy, Precision, Recall, Fscore: [0.67809524 0.68183256 0.67813577 0.67639515]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGpk7TUKBtL5"
      },
      "source": [
        "# Evaluate on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c4JUut1BtBv",
        "outputId": "c4bb76d0-acb6-4ece-9936-54c9a67afd4f"
      },
      "source": [
        "# Finally, check the accuracy of your classifier by training on all the tranin data\n",
        "# and testing on the test set\n",
        "# Will only work once all functions are complete\n",
        "functions_complete = True  # set to True once you're happy with your methods for cross val\n",
        "if functions_complete:\n",
        "    print(testData[0])   # have a look at the first test data instance\n",
        "    classifier = trainClassifier(trainData)  # train the classifier\n",
        "    testTrue = [t[1] for t in testData]   # get the ground-truth labels from the data\n",
        "    testPred = predictLabels(testData, classifier)  # classify the test data to get predicted labels\n",
        "    finalScores = precision_recall_fscore_support(testTrue, testPred, average='weighted') # evaluate\n",
        "    print(\"Done training!\")\n",
        "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % finalScores[:3])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'this': 1, 'assortment': 1, 'really': 1, 'hershey': 1, 'best': 1, 'the': 1, 'little': 1, 'one': 1, 'always': 1, 'excited': 1, 'whenever': 1, 'holiday': 1, 'come': 1}, 'fake')\n",
            "Training Classifier...\n",
            "Done training!\n",
            "Precision: 0.643443\n",
            "Recall: 0.640476\n",
            "F Score:0.638608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXMY-BgKgkCh"
      },
      "source": [
        "# **introducing the bigrams and test linearsvc function with different C values have more improvement than previous method.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uauDqITVFdfp"
      },
      "source": [
        "#Question 5. Pick three of these metadata types to use as additional features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnBBNX--HHht"
      },
      "source": [
        "# load data from a file and append it to the rawData\n",
        "# We pick product_category, porduct title, review title\n",
        "def loadData(path, Text=None):\n",
        "    with open(path) as f:\n",
        "        reader = csv.reader(f, delimiter='\\t')\n",
        "        for line in reader:\n",
        "            (Id, product_category, product_title, review_title, Text, Label) = parseReview(line)\n",
        "            rawData.append((Id, product_category, product_title, review_title, Text, Label))\n",
        "            #preprocessedData.append((Id, preProcess(Text), Label))\n",
        "        \n",
        "def splitData(percentage):\n",
        "    dataSamples = len(rawData)\n",
        "    halfOfData = int(len(rawData)/2)\n",
        "    trainingSamples = int((percentage*dataSamples)/2)\n",
        "    for (_, product_category, product_title, review_title, Text, Label) in rawData[:trainingSamples] + rawData[halfOfData:halfOfData+trainingSamples]:\n",
        "        trainData.append((toFeatureVector(product_category, product_title, review_title, preProcess(Text)),Label))\n",
        "    for (_, product_category, product_title, review_title, Text, Label) in rawData[trainingSamples:halfOfData] + rawData[halfOfData+trainingSamples:]:\n",
        "        testData.append((toFeatureVector(product_category, product_title, review_title, preProcess(Text)),Label))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD0pbZxkHKl8"
      },
      "source": [
        "def parseReview(reviewLine):\n",
        "    s=\"\"\n",
        "    if reviewLine[1]==\"__label1__\":\n",
        "        s = \"fake\"\n",
        "    else: \n",
        "        s = \"real\"\n",
        "    return (reviewLine[0], reviewLine[4], reviewLine[6],reviewLine[7], reviewLine[8], s)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7lmY9zSJVGx"
      },
      "source": [
        "table = str.maketrans({key: None for key in string.punctuation})\n",
        "def preProcess(text):\n",
        "    # Should return a list of tokens\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    filtered_tokens=[]\n",
        "    lemmatized_tokens = []\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = text.translate(table)\n",
        "    for w in text.split(\" \"):\n",
        "        if w not in stop_words:\n",
        "            lemmatized_tokens.append(lemmatizer.lemmatize(w.lower()))\n",
        "        filtered_tokens = [' '.join(l) for l in nltk.bigrams(lemmatized_tokens)] + lemmatized_tokens\n",
        "    return filtered_tokens"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_v50mOUJaRU"
      },
      "source": [
        "featureDict = {} # A global dictionary of features\n",
        "\n",
        "def toFeatureVector(product_category, product_title, review_title, tokens):\n",
        "    localDict = {}\n",
        "    \n",
        "#product_category\n",
        "\n",
        "    if product_category not in featureDict:\n",
        "        featureDict[product_category] = 1\n",
        "    else:\n",
        "        featureDict[product_category] += 1\n",
        "            \n",
        "    if product_category not in localDict:\n",
        "        localDict[product_category] = 1\n",
        "    else:\n",
        "        localDict[product_category] += 1\n",
        "        \n",
        "#product_title\n",
        "\n",
        "    if product_title not in featureDict:\n",
        "        featureDict[product_title] = 1\n",
        "    else:\n",
        "        featureDict[product_title] += 1\n",
        "            \n",
        "    if product_title not in localDict:\n",
        "        localDict[product_title] = 1\n",
        "    else:\n",
        "        localDict[product_title] += 1\n",
        "\n",
        "#review_title\n",
        "\n",
        "    if review_title not in featureDict:\n",
        "        featureDict[review_title] = 1\n",
        "    else:\n",
        "        featureDict[review_title] += 1\n",
        "            \n",
        "    if review_title not in localDict:\n",
        "        localDict[review_title] = 1\n",
        "    else:\n",
        "        localDict[review_title] += 1\n",
        "            \n",
        "#Text        \n",
        "\n",
        "    for token in tokens:\n",
        "        if token not in featureDict:\n",
        "            featureDict[token] = 1\n",
        "        else:\n",
        "            featureDict[token] += 1\n",
        "            \n",
        "        if token not in localDict:\n",
        "            localDict[token] = 1\n",
        "        else:\n",
        "            localDict[token] += 1\n",
        "    \n",
        "    return localDict"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vhAMz-1YMRI",
        "outputId": "0e2428b2-8a80-4819-82c3-609060cfcc7e"
      },
      "source": [
        "# MAIN\n",
        "\n",
        "# loading reviews\n",
        "# initialize global lists that will be appended to by the methods below\n",
        "rawData = []          # the filtered data from the dataset file (should be 21000 samples)\n",
        "trainData = []        # the pre-processed training data as a percentage of the total dataset (currently 80%, or 16800 samples)\n",
        "testData = []         # the pre-processed test data as a percentage of the total dataset (currently 20%, or 4200 samples)\n",
        "\n",
        "# the output classes\n",
        "fakeLabel = 'fake'\n",
        "realLabel = 'real'\n",
        "\n",
        "# references to the data files\n",
        "reviewPath = 'amazon_reviews.txt'\n",
        "\n",
        "# Do the actual stuff (i.e. call the functions we've made)\n",
        "# We parse the dataset and put it in a raw data list\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Preparing the dataset...\",sep='\\n')\n",
        "loadData(reviewPath) \n",
        "\n",
        "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
        "# You do the cross validation on the 80% (training data)\n",
        "# We print the number of training samples and the number of features before the split\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Preparing training and test data...\",sep='\\n')\n",
        "splitData(0.8)\n",
        "# We print the number of training samples and the number of features after the split\n",
        "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Training Samples: \", len(trainData), \"Features: \", len(featureDict), sep='\\n')\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now 0 rawData, 0 trainData, 0 testData\n",
            "Preparing the dataset...\n",
            "Now 21001 rawData, 0 trainData, 0 testData\n",
            "Preparing training and test data...\n",
            "After split, 21001 rawData, 16800 trainData, 4201 testData\n",
            "Training Samples: \n",
            "16800\n",
            "Features: \n",
            "548937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abi7dQKoaDlD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c9359b-acfd-4b8e-8ec7-d66d2519f64f"
      },
      "source": [
        "# crossValidate function on the training set to get your results\n",
        "print(f\"Mean of cross-validations (Accuracy, Precision, Recall, Fscore: {crossValidate(trainData, 10)}\") "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Mean of cross-validations (Accuracy, Precision, Recall, Fscore: [0.68857143 0.69284505 0.68862239 0.68670883]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H07XzORihMXQ"
      },
      "source": [
        "# **Picking three of these metadata types to use as additional features is the most efficient methond among the three, it improves accuracy to a large extent**"
      ]
    }
  ]
}